{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import us # THIS IS AMERICA\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_data_path = \"../data/applemobilitytrends-2020-06-06.csv\"\n",
    "google_data_path = \"../data/Global_Mobility_Report.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_data = pd.read_csv(apple_data_path)\n",
    "google_data = pd.read_csv(google_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Apple Data by County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_data[\"geo_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up grouping by country \n",
    "by_county = apple_data[apple_data[\"geo_type\"] == \"county\"].copy()\n",
    "by_county.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure US is the only country \n",
    "by_county[\"country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only have driving data for this? \n",
    "by_county[\"transportation_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unecessary columns \n",
    "by_county.drop([\"geo_type\", \"alternative_name\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt date columns to rows \n",
    "apple_data_melted = by_county.melt(id_vars=[\"region\", \"transportation_type\", \n",
    "                                            \"sub-region\", \"country\"], \n",
    "                                  var_name=\"date\",\n",
    "                                  value_name=\"mobility_from_baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_data_melted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename cols \n",
    "apple_data_melted.rename({\"sub-region\": \"state\",\n",
    "                          \"region\": \"county\"}, \n",
    "                         axis=1, inplace=True)\n",
    "# apple_data_melted.set_index([\"county\", \"date\"], inplace=True)\n",
    "# apple_data_melted.sort_index().head()\n",
    "# apple_data_melted.reset_index(inplace=True)\n",
    "apple_data_melted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Google Data by County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_data[\"sub_region_1\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_data[\"sub_region_2\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_region 2 is all US counties\n",
    "google_by_county = google_data[~google_data[\"sub_region_2\"].isna()].copy()\n",
    "google_by_county.head() # We want this format for the Apple Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename cols, drop unecessary cols \n",
    "google_by_county.rename({\"sub_region_2\":\"county\",\n",
    "                         \"sub_region_1\":\"state\",\n",
    "                         \"country_region\":\"country\"},\n",
    "                        axis=1, inplace=True)\n",
    "google_by_county.drop(\"country_region_code\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "google_new_index = google_by_county.set_index([\"county\", \"date\"]) # no longer needed \n",
    "google_by_county.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_by_county.reset_index(inplace=True, drop=True)\n",
    "google_by_county.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_data_melted.reset_index(inplace=True, drop=True)\n",
    "apple_data_melted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_include = google_new_index.columns.difference(apple_data_melted.columns) # just want metrics from google\n",
    "cols_to_include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner vs outer has some weird effects ?\n",
    "# merged_data = apple_data_melted.join(google_new_index[cols_to_include], how='inner')\n",
    "# #merged_data.drop([\"country_region\", \"country_region_code\"], axis=1, inplace=True)\n",
    "# merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "apple_data_melted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join drops apple data up to 2/15, so baseline may need to be re-normalized\n",
    "merged_data = pd.merge(google_by_county, apple_data_melted, on=[\"county\", \"state\", \"date\", \"country\"])\n",
    "\n",
    "merged_data.drop(\"country\", axis=1, inplace=True) # omitting country for now "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on baselines:\n",
    "\n",
    "Apple and Google calculated baselines differently. Google's baseline is on a per-weekday basis, while Apple uses a specific day in January as the baseline. Will they need to be re-calculated to be in the same units or does it not matter ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data[merged_data[\"state\"] == \"Florida\"].head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "Both Google and Apple have made sure to leave out mobility data on dates that it is nonexistant or too sparse to apporpriately annonomyse the data. In counties where a particular column is completely NA, we will fill with 0. In counties where there are some dates missing in a column, we will fill NA values with the mean value for that column at that date accross the country. Lastly, Apple has announced that their data for 5/11 and 5/12 are missing, which we will fill with linear interpolation, since this is only a two day gap in data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_na_df = merged_data.apply(pd.isna)\n",
    "sns.heatmap(is_na_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_var = merged_data.groupby(\"date\").agg('std')\n",
    "fig, axs = plt.subplots(7, figsize=(20,30))\n",
    "for i, col in enumerate(mobility_var.columns):\n",
    "    axs[i].plot(mobility_var.index, mobility_var[col])\n",
    "    axs[i].set_title(col)\n",
    "\n",
    "fig.tight_layout(pad=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The parks column has the largest variance and is mostly empty. We may want to consider removing it as a feature. Additionally, it is interesting to see that many of the columns have increasing variance in mobility as time increases. This increase suggests that a division of the population is starting to go out more while there still exists a group that is remaining home. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_example_before = merged_data[(merged_data[\"county\"] == \"Baker County\") &\n",
    "                                (merged_data[\"state\"] == \"Florida\")]\n",
    "na_example_before[\"parks_percent_change_from_baseline\"].isnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fucking ugly code\n",
    "\n",
    "mobility_daily_mean = merged_data.groupby('date').agg('mean')\n",
    "cols = [col for col in mobility_daily_mean if col != \"mobility_from_baseline\"]\n",
    "\n",
    "for group, county_data in merged_data.groupby(['county', 'state']):\n",
    "    apple_col = \"mobility_from_baseline\"\n",
    "    bad_apple_dates = [\"2020-05-11\", \"2020-05-12\"]\n",
    "    county_data.loc[:, apple_col] = county_data.loc[:, apple_col].interpolate(\"linear\").copy()\n",
    "    filled_dates = county_data.loc[county_data[\"date\"].isin(bad_apple_dates), apple_col]\n",
    "    mask = ((merged_data[\"county\"] == group[0]) & \n",
    "            (merged_data[\"state\"] == group[1]) &\n",
    "            (merged_data[\"date\"].isin(bad_apple_dates)), \n",
    "             apple_col)\n",
    "    merged_data.loc[mask] = filled_dates.copy()\n",
    "    \n",
    "    for col in cols:\n",
    "        if county_data[col].isnull().all():\n",
    "            mask = ((merged_data[\"county\"] == group[0]) & \n",
    "                    (merged_data[\"state\"] == group[1]), \n",
    "                    col)\n",
    "            merged_data.loc[mask] = merged_data.loc[mask].fillna(0)\n",
    "        \n",
    "    \n",
    "\n",
    "for date in mobility_daily_mean.index:\n",
    "    for col in cols:\n",
    "        mask = (merged_data[\"date\"] == date, col)\n",
    "        new_val = mobility_daily_mean.loc[date, col]\n",
    "        merged_data.loc[mask] = merged_data.loc[mask].fillna(new_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_example_after = merged_data[(merged_data[\"county\"] == \"Baker County\") &\n",
    "                                (merged_data[\"state\"] == \"Florida\")]\n",
    "na_example_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boom \n",
    "is_na_df = merged_data.apply(pd.isna)\n",
    "sns.heatmap(is_na_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_cases = pd.read_csv(\"https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv\")\n",
    "covid_deaths = pd.read_csv(\"https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_deaths_usafacts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_deaths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = us.states.lookup('AL')\n",
    "print(state.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_data_melted = by_county.melt(id_vars=[\"region\", \"transportation_type\", \n",
    "                                            \"sub-region\", \"country\"], \n",
    "                                  var_name=\"date\",\n",
    "                                  value_name=\"mobility_from_baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_cases = covid_cases.drop([\"countyFIPS\", \"stateFIPS\"], axis=1)\n",
    "covid_cases_melted = covid_cases.melt(id_vars=[\"County Name\", \"State\"],\n",
    "                                      var_name=\"date\",\n",
    "                                      value_name=\"cases\")\n",
    "\n",
    "covid_deaths = covid_deaths.drop([\"countyFIPS\", \"stateFIPS\"], axis=1)\n",
    "covid_deaths_melted = covid_deaths.melt(id_vars=[\"County Name\", \"State\"],\n",
    "                                      var_name=\"date\",\n",
    "                                      value_name=\"deaths\")\n",
    "\n",
    "covid_data = pd.merge(covid_cases_melted, covid_deaths_melted,\n",
    "                      on=[\"County Name\", \"State\", \"date\"])\n",
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks US lib\n",
    "covid_data[\"State\"] = covid_data[\"State\"].apply(lambda x: us.states.lookup(x).name)\n",
    "\n",
    "covid_data.rename({\"County Name\":\"county\",\n",
    "                   \"State\":\"state\"}, axis=1, inplace=True)\n",
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data[\"date\"] = pd.to_datetime(covid_data[\"date\"], infer_datetime_format=True)\n",
    "merged_data[\"date\"] = pd.to_datetime(merged_data[\"date\"], infer_datetime_format=True)\n",
    "\n",
    "all_data = pd.merge(merged_data, covid_data, on=[\"county\", \"state\", \"date\"], how=\"left\")\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_cols = [\n",
    "    \"cases\",\n",
    "    \"deaths\",\n",
    "    \"date\",\n",
    "    \"county\",\n",
    "    \"state\",\n",
    "    \"retail_and_recreation_percent_change_from_baseline\",\n",
    "    \"grocery_and_pharmacy_percent_change_from_baseline\",\n",
    "    \"parks_percent_change_from_baseline\",\n",
    "    \"transit_stations_percent_change_from_baseline\",\n",
    "    \"workplaces_percent_change_from_baseline\",\n",
    "    \"residential_percent_change_from_baseline\",\n",
    "    \"mobility_from_baseline\"\n",
    "]\n",
    "all_data = all_data[ordered_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_date = pd.Timestamp(2020,2,15)\n",
    "all_data[\"date\"] = all_data[\"date\"].apply(lambda x: (x - initial_date).days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 1: make state and county one column and convert to categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_county_categorization = all_data.copy()\n",
    "cols = [\"county\", \"state\"]\n",
    "unique_county_categorization['county'] = unique_county_categorization[cols].apply(\n",
    "                                                lambda row: ', '.join(row.values.astype(str)),\n",
    "                                                axis=1)\n",
    "unique_county_categorization.drop(\"state\", axis=1, inplace=True)\n",
    "unique_county_categorization[\"county\"] = unique_county_categorization[\"county\"].astype(\"category\")\n",
    "county_state_mappings = pd.Series(dict(enumerate(unique_county_categorization['county'].cat.categories)))\n",
    "unique_county_categorization[\"county\"] = unique_county_categorization[\"county\"].cat.codes\n",
    "county_state_mappings.to_csv(\"../data/cleaned_data/dataset_1_categories.csv\")\n",
    "unique_county_categorization.to_csv(\"../data/cleaned_data/dataset_1.csv\")\n",
    "unique_county_categorization.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 2: make state and county unique categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_state_categorization = all_data.copy()\n",
    "county_state_categorization[[\"county\", \"state\"]] = county_state_categorization[[\"county\", \"state\"]].astype(\"category\")\n",
    "county_dict = pd.Series(dict(enumerate(county_state_categorization['county'].cat.categories)))\n",
    "state_dict = pd.Series(dict(enumerate(county_state_categorization['state'].cat.categories)))\n",
    "county_state_categorization[\"county\"] = county_state_categorization[\"county\"].cat.codes\n",
    "county_state_categorization[\"state\"] = county_state_categorization[\"state\"].cat.codes\n",
    "county_state_categorization.to_csv(\"../data/cleaned_data/dataset_2.csv\")\n",
    "county_dict.to_csv(\"../data/cleaned_data/dataset_2_counties.csv\")\n",
    "state_dict.to_csv(\"../data/cleaned_data/dataset_2_states.csv\")\n",
    "county_state_categorization.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 3: Use county populations as factor instead of county/state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data = pd.read_csv(\"https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv\", encoding=\"latin-1\")\n",
    "pop_data = pop_data[[\"STNAME\", \"CTYNAME\", \"POPESTIMATE2019\"]]\n",
    "pop_data.drop(pop_data.loc[pop_data[\"STNAME\"] == pop_data[\"CTYNAME\"]].index, inplace=True)\n",
    "pop_data.rename({\"STNAME\":\"state\",\n",
    "                 \"CTYNAME\":\"county\",\n",
    "                 \"POPESTIMATE2019\":\"county_population\"},\n",
    "               axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_pop = pd.merge(all_data, pop_data, on=[\"state\", \"county\"])\n",
    "all_data_pop.drop([\"county\", \"state\"], axis=1, inplace=True)\n",
    "all_data.to_csv(\"../data/cleaned_data/dataset_3.csv\")\n",
    "all_data_pop.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
